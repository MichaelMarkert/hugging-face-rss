<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Hugging Face Posts</title><link>https://huggingface.co/</link><description>This is a website scraping RSS feed for the Hugginface trending posts.</description><generator>rfeed v1.1.1</generator><docs>https://github.com/svpino/rfeed/blob/master/README.md</docs><item><title>8 New Types of RAG</title><link>https://huggingface.co/posts/Kseniase/113319295427497</link><description>8 New Types of RAG RAG techniques continuously evolve to enhance LLM response accuracy by retrieving relevant external data during generation. To keep up with current AI trends, new RAG types incorporate deep step-by-step reasoning, tree search, citations, multimodality and other effective techniques. Here's a list of 8 latest RAG advancements: 1. DeepRAG -&gt; DeepRAG: Thinking to Retrieval Step by Step for Large Language Models (2502.01142) Models retrieval-augmented reasoning as a Markov Decision Process, enabling strategic retrieval. It dynamically decides when to retrieve external knowledge and when rely on parametric reasoning. 2. RealRAG -&gt; RealRAG: Retrieval-augmented Realistic Image Generation via Self-reflective Contrastive Learning (2502.00848) Enhances novel object generation by retrieving real-world images and using self-reflective contrastive learning to fill knowledge gap, improve realism and reduce distortions. 3. Chain-of-Retrieval Augmented Generation (CoRAG) -&gt;...</description><pubDate>Mon, 10 Feb 2025 17:16:43 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Kseniase/113319295427497</guid></item><item><title>üì¢ New Research Alert: Making Language Models Smaller &amp; Smarter!</title><link>https://huggingface.co/posts/schuler/395413718646507</link><description>üì¢ New Research Alert: Making Language Models Smaller &amp; Smarter! Thrilled to share the latest technical report demonstrating how to reduce language model parameters by 77% while maintaining performance. The secret? Grouped pointwise convolutions. Yes. We brought a method from computer vision to the transformers arena. üîë Key Findings: ‚Ä¢ 77% parameter reduction. ‚Ä¢ Maintained model capabilities. ‚Ä¢ Improved generalization. Paper: https://www.researchgate.net/publication/388835829_SAVING_77_OF_THE_PARAMETERS_IN_LARGE_LANGUAGE_MODELS_TECHNICAL_REPORT Code: https://github.com/joaopauloschuler/less-parameters-llm See translation</description><pubDate>Mon, 10 Feb 2025 17:16:43 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/schuler/395413718646507</guid></item><item><title>Tutorial üí• Training a non-English reasoning model with GRPO and Unsloth</title><link>https://huggingface.co/posts/s-emanuilov/736266652835078</link><description>Tutorial üí• Training a non-English reasoning model with GRPO and Unsloth I wanted to share my experiment with training reasoning models in languages other than English/Chinese. Using Llama 3.1 8B as base, GRPO trainer from trl, and Unsloth optimizations, I got a working prototype in Bulgarian after ~5 hours on an L40S GPU. The approach should work for any language where the base model has some pre-training coverage. Full code and tutorial here: https://unfoldai.com/reasoning-in-a-non-english-language/ The model itself: s-emanuilov/LLMBG-Llama-3.1-8B-BG-Reasoning-v0.1 I hope this helps anyone looking to build reasoning models in their language. See translation</description><pubDate>Mon, 10 Feb 2025 17:16:43 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/s-emanuilov/736266652835078</guid></item><item><title>Fascinating deep dive into Swiggy's Hermes - their in-house Text-to-SQL solution that's revolutionizing data accessibility!</title><link>https://huggingface.co/posts/singhsidhukuldeep/821835295778849</link><description>Fascinating deep dive into Swiggy's Hermes - their in-house Text-to-SQL solution that's revolutionizing data accessibility! Hermes enables natural language querying within Slack, generating and executing SQL queries with an impressive &lt;2 minute turnaround time. The system architecture is particularly intriguing: Technical Implementation: - Built on GPT-4 with a Knowledge Base + RAG approach for Swiggy-specific context - AWS Lambda middleware handles communication between Slack UI and the Gen AI model - Databricks jobs orchestrate query generation and execution Under the Hood: The pipeline employs a sophisticated multi-stage approach: 1. Metrics retrieval using embedding-based vector lookup 2. Table/column identification through metadata descriptions 3. Few-shot SQL retrieval with vector-based search 4. Structured prompt creation with data snapshots 5. Query validation with automated error correction Architecture Highlights: - Compartmentalized by business units (charters) for better...</description><pubDate>Mon, 10 Feb 2025 17:16:43 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/singhsidhukuldeep/821835295778849</guid></item><item><title>QwQ Edge Gets a Small Update..! üí¨</title><link>https://huggingface.co/posts/prithivMLmods/964278651693422</link><description>QwQ Edge Gets a Small Update..! üí¨ try now: prithivMLmods/QwQ-Edge üöÄNow, you can use the following commands for different tasks: üñºÔ∏è @ image 'prompt...' ‚Üí Generates an image üîâ@tts1 'prompt...' ‚Üí Generates speech in a female voice üîâ @ tts2 'prompt...' ‚Üí Generates speech in a male voice üÖ∞Ô∏è@text 'prompt...' ‚Üí Enables textual conversation (If not specified, text-to-text generation is the default mode) üí¨Multimodality Support : prithivMLmods/Qwen2-VL-OCR-2B-Instruct üí¨For text generation, the FastThink-0.5B model ensures quick and efficient responses, prithivMLmods/FastThink-0.5B-Tiny üí¨Image Generation: sdxl lightning model, SG161222/RealVisXL_V4.0_Lightning Github: https://github.com/PRITHIVSAKTHIUR/QwQ-Edge graph TD A[User Interface] --&gt; B[Chat Logic] B --&gt; C{Command Type } C --&gt;| Text | D [FastThink -0.5 B] C --&gt;| Image | E [Qwen2-VL-OCR -2 B] C --&gt;| @image | F [Stable Diffusion XL] C --&gt;| @tts | G [Edge TTS] D --&gt; H[Response] E --&gt; H F --&gt; H G --&gt; H See translation</description><pubDate>Mon, 10 Feb 2025 17:16:43 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/prithivMLmods/964278651693422</guid></item><item><title>VectorFlow ‚ö°: Transform Images into Professional Vector Graphics</title><link>https://huggingface.co/posts/openfree/664271513735189</link><description>VectorFlow ‚ö°: Transform Images into Professional Vector Graphics Convert your raster images (JPG, PNG, WEBP) into high-quality vector graphics (SVG, AI) with our easy-to-use tool! Perfect for designers, artists, and anyone needing vector conversions. üéØ Key Features: Dual format support: SVG and AI output Real-time preview for both formats Advanced customization options Clean, user-friendly interface Batch processing ready üõ†Ô∏è Advanced Controls: Color/B&amp;W mode selection Speckle filtering Color precision adjustment Layer management Curve fitting options üí´ Why VectorFlow? No installation needed Free to use Professional-grade output Simple yet powerful üîß Technical Details: Built with Gradio Powered by VTracer Optimized SVG generation AI format support üëâ Try it now: openfree/VectorFlow #computervision #vectorgraphics #imageprocessing #svg #design #ai See translation</description><pubDate>Mon, 10 Feb 2025 17:16:43 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/openfree/664271513735189</guid></item><item><title>We did it. Kokoro TTS (v1.0) can now run 100% locally in your browser w/ WebGPU acceleration. Real-time text-to-speech without a server. ‚ö°Ô∏è</title><link>https://huggingface.co/posts/Xenova/620657830533509</link><description>We did it. Kokoro TTS (v1.0) can now run 100% locally in your browser w/ WebGPU acceleration. Real-time text-to-speech without a server. ‚ö°Ô∏è Generate 10 seconds of speech in ~1 second for $0. What will you build? üî• webml-community/kokoro-webgpu The most difficult part was getting the model running in the first place, but the next steps are simple: ‚úÇÔ∏è Implement sentence splitting, allowing for streamed responses üåç Multilingual support (only phonemization left) Who wants to help? See translation</description><pubDate>Mon, 10 Feb 2025 17:16:43 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/Xenova/620657830533509</guid></item><item><title>Wanted: Peak Data. I'm collecting audio data to train another TTS model:</title><link>https://huggingface.co/posts/hexgrad/846477530846098</link><description>Wanted: Peak Data. I'm collecting audio data to train another TTS model: + AVM data: ChatGPT Advanced Voice Mode audio &amp; text from source + Professional audio: Permissive (CC0, Apache, MIT, CC-BY) This audio should *impress* most native speakers, not just barely pass their audio Turing tests. Professional-caliber means S or A-tier, not your average bloke off the street. Traditional TTS may not make the cut. Absolutely no low-fi microphone recordings like Common Voice. The bar is much higher than last time, so there are no timelines yet and I expect it may take longer to collect such mythical data. Raising the bar means evicting quite a bit of old data, and voice/language availability may decrease. The theme is *quality* over quantity. I would rather have 1 hour of A/S-tier than 100 hours of mid data. I have nothing to offer but the north star of a future Apache 2.0 TTS model, so prefer data that you *already have* and costs you *nothing extra* to send. Additionally, *all* the new...</description><pubDate>Mon, 10 Feb 2025 17:16:43 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/hexgrad/846477530846098</guid></item><item><title>Researchers developed Sonic AI enabling precise facial animation from speech cues üéß Decouples head/expression control via audio tone analysis + time-aware fusion for natural long-form synthesis</title><link>https://huggingface.co/posts/kadirnar/407959263704733</link><description>Researchers developed Sonic AI enabling precise facial animation from speech cues üéß Decouples head/expression control via audio tone analysis + time-aware fusion for natural long-form synthesis See translation</description><pubDate>Mon, 10 Feb 2025 17:16:43 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/kadirnar/407959263704733</guid></item><item><title>üåü 3D Llama Studio - AI 3D Generation Platform</title><link>https://huggingface.co/posts/ginipick/845644282975973</link><description>üåü 3D Llama Studio - AI 3D Generation Platform üìù Project Overview 3D Llama Studio is an all-in-one AI platform that generates high-quality 3D models and stylized images from text or image inputs. ‚ú® Key Features Text/Image to 3D Conversion üéØ Generate 3D models from detailed text descriptions or reference images Intuitive user interface Text to Styled Image Generation üé® Customizable image generation settings Adjustable resolution, generation steps, and guidance scale Supports both English and Korean prompts üõ†Ô∏è Technical Features Gradio-based web interface Dark theme UI/UX Real-time image generation and 3D modeling üí´ Highlights User-friendly interface Real-time preview Random seed generation High-resolution output support (up to 2048x2048) üéØ Applications Product design Game asset creation Architectural visualization Educational 3D content üîó Try It Now! Experience 3D Llama Studio: ginigen/3D-LLAMA #AI #3DGeneration #MachineLearning #ComputerVision #DeepLearning See translation</description><pubDate>Mon, 10 Feb 2025 17:16:43 GMT</pubDate><guid isPermaLink="true">https://huggingface.co/posts/ginipick/845644282975973</guid></item></channel></rss>