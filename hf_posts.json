{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/burtenshaw/457613029588941", "image": "", "title": "The Hugging Face agents course is finally out!", "content_text": "The Hugging Face agents course is finally out! \ud83d\udc49 https://huggingface.co/agents-course This first unit of the course sets you up with all the fundamentals to become a pro in agents. - What's an AI Agent? - What are LLMs? - Messages and Special Tokens - Understanding AI Agents through the Thought-Action-Observation Cycle - Thought, Internal Reasoning and the Re-Act Approach - Actions, Enabling the Agent to Engage with Its Environment - Observe, Integrating Feedback to Reflect and Adapt See translation", "url": "https://huggingface.co/posts/burtenshaw/457613029588941", "date_published": "2025-02-14T05:19:44.561353"}, {"id": "https://huggingface.co/posts/jasoncorkill/476446672223675", "image": "", "title": "Runway Gen-3 Alpha: The Style and Coherence Champion", "content_text": "Runway Gen-3 Alpha: The Style and Coherence Champion Runway's latest video generation model, Gen-3 Alpha, is something special. It ranks #3 overall on our text-to-video human preference benchmark, but in terms of style and coherence, it outperforms even OpenAI Sora. However, it struggles with alignment, making it less predictable for controlled outputs. We've released a new dataset with human evaluations of Runway Gen-3 Alpha: Rapidata's text-2-video human preferences dataset. If you're working on video generation and want to see how your model compares to the biggest players, we can benchmark it for you. \ud83d\ude80 DM us if you\u2019re interested! Dataset: Rapidata/text-2-video-human-preferences-runway-alpha See translation", "url": "https://huggingface.co/posts/jasoncorkill/476446672223675", "date_published": "2025-02-14T05:19:44.561751"}, {"id": "https://huggingface.co/posts/m-ric/116861695030454", "image": "", "title": "\"\ud835\udfee\ud835\udfec\ud835\udfee\ud835\udff1 \ud835\ude04\ud835\uddf6\ud835\uddf9\ud835\uddf9 \ud835\uddef\ud835\uddf2 \ud835\ude01\ud835\uddf5\ud835\uddf2 \ud835\ude06\ud835\uddf2\ud835\uddee\ud835\uddff \ud835\uddfc\ud835\uddf3 \ud835\uddd4\ud835\udddc \ud835\uddee\ud835\uddf4\ud835\uddf2\ud835\uddfb\ud835\ude01\ud835\ude00\": this statement has often been made, here are numbers to support it.", "content_text": "\"\ud835\udfee\ud835\udfec\ud835\udfee\ud835\udff1 \ud835\ude04\ud835\uddf6\ud835\uddf9\ud835\uddf9 \ud835\uddef\ud835\uddf2 \ud835\ude01\ud835\uddf5\ud835\uddf2 \ud835\ude06\ud835\uddf2\ud835\uddee\ud835\uddff \ud835\uddfc\ud835\uddf3 \ud835\uddd4\ud835\udddc \ud835\uddee\ud835\uddf4\ud835\uddf2\ud835\uddfb\ud835\ude01\ud835\ude00\": this statement has often been made, here are numbers to support it. I've plotted the progress of AI agents on GAIA test set, and it seems they're headed to catch up with the human baseline in early 2026. And that progress is still driven mostly by the improvement of base LLMs: progress would be even faster with fine-tuned agentic models. See translation", "url": "https://huggingface.co/posts/m-ric/116861695030454", "date_published": "2025-02-14T05:19:44.562068"}, {"id": "https://huggingface.co/posts/ZennyKenny/584467772865203", "image": "", "title": "I've completed the first unit of the just-launched Hugging Face Agents Course. I would highly recommend it, even for experienced builders, because it is a great walkthrough of the smolagents library and toolkit.", "content_text": "I've completed the first unit of the just-launched Hugging Face Agents Course. I would highly recommend it, even for experienced builders, because it is a great walkthrough of the smolagents library and toolkit. See translation", "url": "https://huggingface.co/posts/ZennyKenny/584467772865203", "date_published": "2025-02-14T05:19:44.562309"}, {"id": "https://huggingface.co/posts/etemiz/440192103698875", "image": "", "title": "Some things are simple", "content_text": "Some things are simple See translation", "url": "https://huggingface.co/posts/etemiz/440192103698875", "date_published": "2025-02-14T05:19:44.562504"}, {"id": "https://huggingface.co/posts/jsulz/515376333515070", "image": "", "title": "Toward the end of last year, the Xet team provided an inside look into the foundations of how we plan to enable rapid experimentation and iteration for the AI builders on the Hub:", "content_text": "Toward the end of last year, the Xet team provided an inside look into the foundations of how we plan to enable rapid experimentation and iteration for the AI builders on the Hub: https://huggingface.co/blog/from-files-to-chunks But it turns out chunks aren't all you need! Our goal is to bring: \ud83d\ude80 Faster uploads \u23ec Speedy downloads \ud83d\udcaa All without sacrificing your workflow To do that, we need the infrastructure and system and design to back it up. As we prepare to roll out the first Xet-backed repositories on the Hub, we wrote up a post explaining the nitty gritty details of the decisions that bring this to life https://huggingface.co/blog/from-chunks-to-blocks Complete with an interactive visualization that shows the power of deduplication in action - taking a 191GB repo to ~97GB and shaving a few hours off upload speeds. The darker each block in the heatmap, the more we dedupe, the less we have to transfer. Clicking on a file's blocks shows all other files that share blocks. Check it...", "url": "https://huggingface.co/posts/jsulz/515376333515070", "date_published": "2025-02-14T05:19:44.562987"}, {"id": "https://huggingface.co/posts/AdinaY/720327371561767", "image": "", "title": "InspireMusic \ud83c\udfb5\ud83d\udd25 an open music generation framework by Alibaba FunAudio Lab", "content_text": "InspireMusic \ud83c\udfb5\ud83d\udd25 an open music generation framework by Alibaba FunAudio Lab Model: FunAudioLLM/InspireMusic-1.5B-Long Demo: FunAudioLLM/InspireMusic \u2728 Music, songs, audio - ALL IN ONE \u2728 High quality audio: 24kHz & 48kHz sampling rates \u2728 Long-Form Generation: enables extended audio creation \u2728 Efficient Fine-Tuning: precision (BF16, FP16, FP32) with user-friendly scripts See translation", "url": "https://huggingface.co/posts/AdinaY/720327371561767", "date_published": "2025-02-14T05:19:44.563301"}, {"id": "https://huggingface.co/posts/fantos/903293233196599", "image": "", "title": "\ud83d\ude0a Panorama X3 Image", "content_text": "\ud83d\ude0a Panorama X3 Image an innovative system that leverages a Stable Diffusion XL-based tiling pipeline to generate unique and vibrant panoramic images by applying different prompts to the left, center, and right sections of a single image. Key Features & Strengths Multi-Area Prompt Support Input distinct descriptions for the left, center, and right regions (e.g., \"dense forest\" for the left, \"calm lake\" for the center, and \"majestic mountains\" for the right). This allows the system to seamlessly blend multiple scenes into one stunning panoramic image. \ud83c\udf04 Automatic Korean-to-English Translation If your prompt contains Korean text, it will be automatically translated into English before image generation. (For example, \"\uc548\uac1c \ub080 \uc0b0\" becomes \"Misty mountain\") \ud83d\udd04 This feature ensures that you can effortlessly use both English and Korean prompts. Advanced Tiling Technology The project uses a sophisticated tiling approach that manages overlapping regions to produce natural transitions and high-...", "url": "https://huggingface.co/posts/fantos/903293233196599", "date_published": "2025-02-14T05:19:44.563898"}, {"id": "https://huggingface.co/posts/fdaudens/212771868233348", "image": "", "title": "\u2b50\ufe0f The AI Energy Score project just launched - this is a game-changer for making informed decisions about AI deployment.", "content_text": "\u2b50\ufe0f The AI Energy Score project just launched - this is a game-changer for making informed decisions about AI deployment. You can now see exactly how much energy your chosen model will consume, with a simple 5-star rating system. Think appliance energy labels, but for AI. Looking at transcription models on the leaderboard is fascinating: choosing between whisper-tiny or whisper-large-v3 can make a 7x difference. Real-time data on these tradeoffs changes everything. 166 models already evaluated across 10 different tasks, from text generation to image classification. The whole thing is public and you can submit your own models to test. Why this matters: - Teams can pick efficient models that still get the job done - Developers can optimize for energy use from day one - Organizations can finally predict their AI environmental impact If you're building with AI at any scale, definitely worth checking out. \ud83d\udc49 leaderboard: https://lnkd.in/esrSxetj \ud83d\udc49 blog post: https://lnkd.in/eFJvzHi8 Huge...", "url": "https://huggingface.co/posts/fdaudens/212771868233348", "date_published": "2025-02-14T05:19:44.564396"}, {"id": "https://huggingface.co/posts/lukmanaj/991201381303884", "image": "", "title": "I am excited to share that I\u2019ve successfully completed Unit 1: Foundations of Agents in the Hugging Face Agents Course.", "content_text": "I am excited to share that I\u2019ve successfully completed Unit 1: Foundations of Agents in the Hugging Face Agents Course. Exploring the fundamentals of AI agents has been an insightful journey, and I\u2019m looking forward to applying these concepts in real-world applications. Big thanks to the Hugging Face team for this amazing learning opportunity! \ud83e\udd17 Check out the course here: https://huggingface.co/learn/agents-course/ See translation", "url": "https://huggingface.co/posts/lukmanaj/991201381303884", "date_published": "2025-02-14T05:19:44.564692"}]}