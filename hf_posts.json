{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/burtenshaw/457613029588941", "image": "", "title": "The Hugging Face agents course is finally out!", "content_text": "The Hugging Face agents course is finally out! \ud83d\udc49 https://huggingface.co/agents-course This first unit of the course sets you up with all the fundamentals to become a pro in agents. - What's an AI Agent? - What are LLMs? - Messages and Special Tokens - Understanding AI Agents through the Thought-Action-Observation Cycle - Thought, Internal Reasoning and the Re-Act Approach - Actions, Enabling the Agent to Engage with Its Environment - Observe, Integrating Feedback to Reflect and Adapt See translation", "url": "https://huggingface.co/posts/burtenshaw/457613029588941", "date_published": "2025-02-13T09:22:07.346640"}, {"id": "https://huggingface.co/posts/fantos/903293233196599", "image": "", "title": "\ud83d\ude0a Panorama X3 Image", "content_text": "\ud83d\ude0a Panorama X3 Image an innovative system that leverages a Stable Diffusion XL-based tiling pipeline to generate unique and vibrant panoramic images by applying different prompts to the left, center, and right sections of a single image. Key Features & Strengths Multi-Area Prompt Support Input distinct descriptions for the left, center, and right regions (e.g., \"dense forest\" for the left, \"calm lake\" for the center, and \"majestic mountains\" for the right). This allows the system to seamlessly blend multiple scenes into one stunning panoramic image. \ud83c\udf04 Automatic Korean-to-English Translation If your prompt contains Korean text, it will be automatically translated into English before image generation. (For example, \"\uc548\uac1c \ub080 \uc0b0\" becomes \"Misty mountain\") \ud83d\udd04 This feature ensures that you can effortlessly use both English and Korean prompts. Advanced Tiling Technology The project uses a sophisticated tiling approach that manages overlapping regions to produce natural transitions and high-...", "url": "https://huggingface.co/posts/fantos/903293233196599", "date_published": "2025-02-13T09:22:07.347245"}, {"id": "https://huggingface.co/posts/ginipick/776720011919298", "image": "", "title": "Time Stream \u23f3\ud83d\ude80", "content_text": "Time Stream \u23f3\ud83d\ude80 Time Stream is a groundbreaking AI tool that transforms your text into a mesmerizing video journey from the past to the future. With this innovative technology, your ideas evolve over time, visualized through a dynamic image strip and a fluid video narrative. Imagine typing a simple prompt and watching as your words transform into vivid scenes that capture every moment of change\u2014like a time machine for creativity! \ud83c\udfa5\u2728 Key Features: \u2022 Text-to-Video Transformation: Enter any text, and Time Stream converts it into a compelling video that travels through time, turning your ideas into a visual story. \ud83d\udcfd\ufe0f \u2022 Dynamic Image Strip: Alongside the video, a vibrant image strip is created, showcasing each stage of the transformation so you can see every detail of the evolution. \ud83d\udcf8 \u2022 Customizable Settings: Adjust parameters such as strength, guidance scale, and more to fine-tune your video\u2019s appearance and ensure it perfectly matches your creative vision. \u2699\ufe0f \u2022 User-Friendly Interface:...", "url": "https://huggingface.co/posts/ginipick/776720011919298", "date_published": "2025-02-13T09:22:07.347834"}, {"id": "https://huggingface.co/posts/jasoncorkill/476446672223675", "image": "", "title": "Runway Gen-3 Alpha: The Style and Coherence Champion", "content_text": "Runway Gen-3 Alpha: The Style and Coherence Champion Runway's latest video generation model, Gen-3 Alpha, is something special. It ranks #3 overall on our text-to-video human preference benchmark, but in terms of style and coherence, it outperforms even OpenAI Sora. However, it struggles with alignment, making it less predictable for controlled outputs. We've released a new dataset with human evaluations of Runway Gen-3 Alpha: Rapidata's text-2-video human preferences dataset. If you're working on video generation and want to see how your model compares to the biggest players, we can benchmark it for you. \ud83d\ude80 DM us if you\u2019re interested! Dataset: Rapidata/text-2-video-human-preferences-runway-alpha See translation", "url": "https://huggingface.co/posts/jasoncorkill/476446672223675", "date_published": "2025-02-13T09:22:07.348214"}, {"id": "https://huggingface.co/posts/ZennyKenny/584467772865203", "image": "", "title": "I've completed the first unit of the just-launched Hugging Face Agents Course. I would highly recommend it, even for experienced builders, because it is a great walkthrough of the smolagents library and toolkit.", "content_text": "I've completed the first unit of the just-launched Hugging Face Agents Course. I would highly recommend it, even for experienced builders, because it is a great walkthrough of the smolagents library and toolkit. See translation", "url": "https://huggingface.co/posts/ZennyKenny/584467772865203", "date_published": "2025-02-13T09:22:07.348449"}, {"id": "https://huggingface.co/posts/elismasilva/251775641926329", "image": "", "title": "Mixture-of-Diffusers pipeline tiling for SDXL", "content_text": "Mixture-of-Diffusers pipeline tiling for SDXL This strives to provide a better tool for image composition by using several diffusion processes in parallel, each configured with a specific prompt and settings, and focused on a particular region of the image. The mixture of diffusion processes is done in a way that harmonizes the generation process, preventing \"seam\" effects in the generated image. Using several diffusion processes in parallel has also practical advantages when generating very large images, as the GPU memory requirements are similar to that of generating an image of the size of a single tile. elismasilva/mixture-of-diffusers-sdxl-tiling See translation", "url": "https://huggingface.co/posts/elismasilva/251775641926329", "date_published": "2025-02-13T09:22:07.348779"}, {"id": "https://huggingface.co/posts/DualityAI-RebekahBogdanoff/603171026598171", "image": "", "title": "This Friday at 11 pm ET, Duality.ai is offering a free course on creating realistic materials in simulation.", "content_text": "This Friday at 11 pm ET, Duality.ai is offering a free course on creating realistic materials in simulation. https://forms.gle/iHjqojKUEJZ3EU7w6 Crafting data in simulation that is indistinguishable from the physical world is essential for bridging the sim2real gap. Physically Based Rendering, or PBR, materials play a huge role in realism. Join us the Friday to learn more. Duality.ai has been successful in using game engine simulation to create synthetic data that jumps the sim2 real gap for many commercial clients including JPL-NASA, AWS, P&G, and more. Check out our educational content to access the software and the work flow that makes this possible https://www.duality.ai/edu See translation", "url": "https://huggingface.co/posts/DualityAI-RebekahBogdanoff/603171026598171", "date_published": "2025-02-13T09:22:07.349093"}, {"id": "https://huggingface.co/posts/ImranzamanML/161215925152068", "image": "", "title": "Hugging Face just launched the AI Agents Course \u2013 a free journey from beginner to expert in AI agents!", "content_text": "Hugging Face just launched the AI Agents Course \u2013 a free journey from beginner to expert in AI agents! - Learn AI Agent fundamentals, use cases and frameworks - Use top libraries like LangChain & LlamaIndex - Compete in challenges & earn a certificate - Hands-on projects & real-world applications https://huggingface.co/learn/agents-course/unit0/introduction You can join for a live Q&A on Feb 12 at 5PM CET to learn more about the course here https://www.youtube.com/live/PopqUt3MGyQ See translation", "url": "https://huggingface.co/posts/ImranzamanML/161215925152068", "date_published": "2025-02-13T09:22:07.349420"}, {"id": "https://huggingface.co/posts/m-ric/116861695030454", "image": "", "title": "\"\ud835\udfee\ud835\udfec\ud835\udfee\ud835\udff1 \ud835\ude04\ud835\uddf6\ud835\uddf9\ud835\uddf9 \ud835\uddef\ud835\uddf2 \ud835\ude01\ud835\uddf5\ud835\uddf2 \ud835\ude06\ud835\uddf2\ud835\uddee\ud835\uddff \ud835\uddfc\ud835\uddf3 \ud835\uddd4\ud835\udddc \ud835\uddee\ud835\uddf4\ud835\uddf2\ud835\uddfb\ud835\ude01\ud835\ude00\": this statement has often been made, here are numbers to support it.", "content_text": "\"\ud835\udfee\ud835\udfec\ud835\udfee\ud835\udff1 \ud835\ude04\ud835\uddf6\ud835\uddf9\ud835\uddf9 \ud835\uddef\ud835\uddf2 \ud835\ude01\ud835\uddf5\ud835\uddf2 \ud835\ude06\ud835\uddf2\ud835\uddee\ud835\uddff \ud835\uddfc\ud835\uddf3 \ud835\uddd4\ud835\udddc \ud835\uddee\ud835\uddf4\ud835\uddf2\ud835\uddfb\ud835\ude01\ud835\ude00\": this statement has often been made, here are numbers to support it. I've plotted the progress of AI agents on GAIA test set, and it seems they're headed to catch up with the human baseline in early 2026. And that progress is still driven mostly by the improvement of base LLMs: progress would be even faster with fine-tuned agentic models. See translation", "url": "https://huggingface.co/posts/m-ric/116861695030454", "date_published": "2025-02-13T09:22:07.349732"}, {"id": "https://huggingface.co/posts/davidberenstein1957/431407905900300", "image": "", "title": "\ud83d\ude80 Find banger tools for your smolagents!", "content_text": "\ud83d\ude80 Find banger tools for your smolagents! I created the Tools gallery, which makes tools specifically developed by/for smolagents searchable and visible. This will help with: - inspiration - best practices - finding cool tools Space: davidberenstein1957/smolagents-and-tools See translation", "url": "https://huggingface.co/posts/davidberenstein1957/431407905900300", "date_published": "2025-02-13T09:22:07.349997"}]}