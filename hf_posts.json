{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/etemiz/440192103698875", "image": "", "title": "Some things are simple", "content_text": "Some things are simple See translation", "url": "https://huggingface.co/posts/etemiz/440192103698875", "date_published": "2025-02-15T13:20:20.697468"}, {"id": "https://huggingface.co/posts/AdinaY/720327371561767", "image": "", "title": "InspireMusic \ud83c\udfb5\ud83d\udd25 an open music generation framework by Alibaba FunAudio Lab", "content_text": "InspireMusic \ud83c\udfb5\ud83d\udd25 an open music generation framework by Alibaba FunAudio Lab Model: FunAudioLLM/InspireMusic-1.5B-Long Demo: FunAudioLLM/InspireMusic \u2728 Music, songs, audio - ALL IN ONE \u2728 High quality audio: 24kHz & 48kHz sampling rates \u2728 Long-Form Generation: enables extended audio creation \u2728 Efficient Fine-Tuning: precision (BF16, FP16, FP32) with user-friendly scripts See translation", "url": "https://huggingface.co/posts/AdinaY/720327371561767", "date_published": "2025-02-15T13:20:20.697802"}, {"id": "https://huggingface.co/posts/merve/171433424068357", "image": "", "title": "Your weekly recap of open AI is here, and it's packed with models!", "content_text": "Your weekly recap of open AI is here, and it's packed with models! merve/feb-14-releases-67af876b404cc27c6d837767 \ud83d\udc40 Multimodal > OpenGVLab released InternVideo 2.5 Chat models, new video LMs with long context > AIDC released Ovis2 model family along with Ovis dataset, new vision LMs in different sizes (1B, 2B, 4B, 8B, 16B, 34B), with video and OCR support > ColQwenStella-2b is a multilingual visual retrieval model that is sota in it's size > Hoags-2B-Exp is a new multilingual vision LM with contextual reasoning, long context video understanding \ud83d\udcac LLMs A lot of math models! > Open-R1 team released OpenR1-Math-220k large scale math reasoning dataset, along with Qwen2.5-220K-Math fine-tuned on the dataset, OpenR1-Qwen-7B > Nomic AI released new Nomic Embed multilingual retrieval model, a MoE with 500 params with 305M active params, outperforming other models > DeepScaleR-1.5B-Preview is a new DeepSeek-R1-Distill fine-tune using distributed RL on math > LIMO is a new fine-tune of...", "url": "https://huggingface.co/posts/merve/171433424068357", "date_published": "2025-02-15T13:20:20.698325"}, {"id": "https://huggingface.co/posts/fdaudens/212771868233348", "image": "", "title": "\u2b50\ufe0f The AI Energy Score project just launched - this is a game-changer for making informed decisions about AI deployment.", "content_text": "\u2b50\ufe0f The AI Energy Score project just launched - this is a game-changer for making informed decisions about AI deployment. You can now see exactly how much energy your chosen model will consume, with a simple 5-star rating system. Think appliance energy labels, but for AI. Looking at transcription models on the leaderboard is fascinating: choosing between whisper-tiny or whisper-large-v3 can make a 7x difference. Real-time data on these tradeoffs changes everything. 166 models already evaluated across 10 different tasks, from text generation to image classification. The whole thing is public and you can submit your own models to test. Why this matters: - Teams can pick efficient models that still get the job done - Developers can optimize for energy use from day one - Organizations can finally predict their AI environmental impact If you're building with AI at any scale, definitely worth checking out. \ud83d\udc49 leaderboard: https://lnkd.in/esrSxetj \ud83d\udc49 blog post: https://lnkd.in/eFJvzHi8 Huge...", "url": "https://huggingface.co/posts/fdaudens/212771868233348", "date_published": "2025-02-15T13:20:20.698820"}, {"id": "https://huggingface.co/posts/burtenshaw/555593095351748", "image": "", "title": "Hey, I\u2019m Ben and I work at Hugging Face.", "content_text": "Hey, I\u2019m Ben and I work at Hugging Face. Right now, I\u2019m focusing on educational stuff and getting loads of new people to build open AI models using free and open source tools. I\u2019ve made a collection of some of the tools I\u2019m building and using for teaching. Stuff like quizzes, code challenges, and certificates. burtenshaw/tools-for-learning-ai-6797453caae193052d3638e2 See translation", "url": "https://huggingface.co/posts/burtenshaw/555593095351748", "date_published": "2025-02-15T13:20:20.699120"}, {"id": "https://huggingface.co/posts/MonsterMMORPG/156738682781025", "image": "", "title": "RTX 5090 Tested Against FLUX DEV, SD 3.5 Large, SD 3.5 Medium, SDXL, SD 1.5 with AMD 9950X CPU and RTX 5090 compared against RTX 3090 TI in all benchmarks. Moreover, compared FP8 vs FP16 and changing prompt impact as well", "content_text": "RTX 5090 Tested Against FLUX DEV, SD 3.5 Large, SD 3.5 Medium, SDXL, SD 1.5 with AMD 9950X CPU and RTX 5090 compared against RTX 3090 TI in all benchmarks. Moreover, compared FP8 vs FP16 and changing prompt impact as well Video Link : https://youtu.be/jHlGzaDLkto In this video I have intensively compared RTX 5090 speed on FLUX DEV, FLUX Fill, SD 3.5 Large, SD 3.5 Medium, Stable Diffusion XL (SDXL) and Stable Diffusion 1.5 (SD 1.5) models. For each benchmark, I have compared RTX 5090 against RTX 3090 TI so we see the speed improvement. Moreover, I have tested FP8 vs 16-bit precision for FLUX and SD 3.5 Large and SD 3.5 Medium models. Furthermore, I have tested the speed impact of changing prompt on FLUX DEV model since one of the follower had requested. Full specs of the system provided below. I have used SwarmUI with ComfyUI backend so these benchmarks are literally done on ComfyUI you can think as. Currently no other interface / UI supporting RTX 5000 series as far as i know. Video...", "url": "https://huggingface.co/posts/MonsterMMORPG/156738682781025", "date_published": "2025-02-15T13:20:20.699773"}, {"id": "https://huggingface.co/posts/m-ric/668305263865285", "image": "", "title": "\ud835\uddda\ud835\uddff\ud835\uddf2\ud835\uddee\ud835\ude01 \ud835\uddf3\ud835\uddf2\ud835\uddee\ud835\ude01\ud835\ude02\ud835\uddff\ud835\uddf2 \ud835\uddee\ud835\uddf9\ud835\uddf2\ud835\uddff\ud835\ude01: you can now share agents to the Hub! \ud83e\udd73\ud83e\udd73", "content_text": "\ud835\uddda\ud835\uddff\ud835\uddf2\ud835\uddee\ud835\ude01 \ud835\uddf3\ud835\uddf2\ud835\uddee\ud835\ude01\ud835\ude02\ud835\uddff\ud835\uddf2 \ud835\uddee\ud835\uddf9\ud835\uddf2\ud835\uddff\ud835\ude01: you can now share agents to the Hub! \ud83e\udd73\ud83e\udd73 And any agent pushed to Hub get a cool Space interface to directly chat with it. This was a real technical challenge: for instance, serializing tools to export them meant that you needed to get all the source code for a tool, verify that it was standalone (not relying on external variables), and gathering all the packages required to make it run. Go try it out! \ud83d\udc49 https://github.com/huggingface/smolagents See translation", "url": "https://huggingface.co/posts/m-ric/668305263865285", "date_published": "2025-02-15T13:20:20.700098"}, {"id": "https://huggingface.co/posts/m-ric/573811868569071", "image": "", "title": "For those who haven't come across it yet, here's a handy trick to discuss an entire GitHub repo with an LLM:", "content_text": "For those who haven't come across it yet, here's a handy trick to discuss an entire GitHub repo with an LLM: => Just replace \"github\" with \"gitingest\" in the url, and you get the whole repo as a single string that you can then paste in your LLMs See translation", "url": "https://huggingface.co/posts/m-ric/573811868569071", "date_published": "2025-02-15T13:20:20.700346"}, {"id": "https://huggingface.co/posts/Duskfallcrew/566792357846596", "image": "", "title": "I don't have the stamina to port my articles tonight, i've been dealign with my CPTSD seizures again - but here's a fun update over on Bluesky!", "content_text": "I don't have the stamina to port my articles tonight, i've been dealign with my CPTSD seizures again - but here's a fun update over on Bluesky! https://bsky.app/profile/duskfallcrew.bsky.social/post/3li4zwdhy5c2q HF's been my open source home since before i got on Civitai, and while i've largely left Civitai, i can't leave AI yet. SO if y'all don't mind me trying to rebuild my \"empire\" one nerd block at a time, i'll keep my content easily accessible, :) OH PSST New AI/ML Discord i made recently: (It's also a shill for my main twitch/media/music hub) Join us on this journey. Welcome to Ktiseos Nyx. Our Discord: https://discord.gg/HhBSvM9gBY Earth & Dusk Media https://discord.gg/5t2kYxt7An :3 Cant' wait to hang out, and i've always linked back to HF for my E&D. content in terms of my lora backups and checkpoints! Y'all who make diffusers versions of my content: YOU ROCK. Do me a smidge favor: :3 aside from linking back can you maaaaaybe add the new K/N discord on there? it's my geeky...", "url": "https://huggingface.co/posts/Duskfallcrew/566792357846596", "date_published": "2025-02-15T13:20:20.700751"}, {"id": "https://huggingface.co/posts/onekq/665614273291990", "image": "", "title": "R1 is still trending. Here is a collection of works trying to replicate R1.", "content_text": "R1 is still trending. Here is a collection of works trying to replicate R1. onekq-ai/r1-reproduction-works-67a93f2fb8b21202c9eedf0b Players include Huggingface (Open R1), Stanford (simple scaling), Berkeley (Bespoke, Open thoughts, etc.), ServiceNow, etc. I know there is another work from HKUST but couldn't find it on \ud83e\udd17. Let me know if I miss any teams. See translation", "url": "https://huggingface.co/posts/onekq/665614273291990", "date_published": "2025-02-15T13:20:20.701039"}]}