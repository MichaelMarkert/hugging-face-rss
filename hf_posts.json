{"version": "https://jsonfeed.org/version/1", "title": "Hugging Face Posts", "home_page_url": "https://huggingface.co/", "feed_url": "https://raw.githubusercontent.com/MichaelMarkert/rss/refs/heads/main/hf_posts.json", "items": [{"id": "https://huggingface.co/posts/hexgrad/562263062112849", "image": "", "title": "I wrote an article about G2P:", "content_text": "I wrote an article about G2P: https://hf.co/blog/hexgrad/g2p G2P is an underrated piece of small TTS models, like offensive linemen who do a bunch of work and get no credit. Instead of relying on explicit G2P, larger speech models implicitly learn this task by eating many thousands of hours of audio data. They often use a 500M+ parameter LLM at the front to predict latent audio tokens over a learned codebook, then decode these tokens into audio. Kokoro instead relies on G2P preprocessing, is 82M parameters, and thus needs less audio to learn. Because of this, we can cherrypick high fidelity audio for training data, and deliver solid speech for those voices. In turn, this excellent audio quality & lack of background noise helps explain why Kokoro is very competitive in single-voice TTS Arenas. See translation", "url": "https://huggingface.co/posts/hexgrad/562263062112849", "date_published": "2025-02-07T17:01:45.530309"}, {"id": "https://huggingface.co/posts/retronic/114797173531800", "image": "", "title": "Colox, a reasoning AI model. I am currently working on a model smarter than GPT o1 that thinks before it speaks. It is coming tomorrow in the afternoon.", "content_text": "Colox, a reasoning AI model. I am currently working on a model smarter than GPT o1 that thinks before it speaks. It is coming tomorrow in the afternoon. See translation", "url": "https://huggingface.co/posts/retronic/114797173531800", "date_published": "2025-02-07T17:01:45.530570"}, {"id": "https://huggingface.co/posts/lin-tan/763019179488759", "image": "", "title": "\ud83d\ude80 Excited to share that our paper, \"SELP: Generating Safe and Efficient Task Plans for Robot Agents with Large Language Models\", has been accepted to #ICRA2025! \ud83d\udd17 Preprint:", "content_text": "\ud83d\ude80 Excited to share that our paper, \"SELP: Generating Safe and Efficient Task Plans for Robot Agents with Large Language Models\", has been accepted to #ICRA2025! \ud83d\udd17 Preprint: https://arxiv.org/pdf/2409.19471 We introduce SELP (Safe Efficient LLM Planner), a novel approach for generating plans that adhere to user-specified constraints while optimizing for time-efficient execution. By leveraging linear temporal logic (LTL) to interpret natural language commands, SELP effectively handles complex commands and long-horizon tasks. \ud83e\udd16 \ud83d\udca1SELP presents three key insights: 1\ufe0f\u20e3 Equivalence Voting: Ensures robust translations from natural language instructions into LTL specifications. 2\ufe0f\u20e3 Constrained Decoding: Uses the generated LTL formula to guide the autoregressive inference of plans, ensuring the generated plans conform to the LTL. 3\ufe0f\u20e3 Domain-Specific Fine-Tuning: Customizes LLMs for specific robotic tasks, boosting both safety and efficiency. \ud83d\udcca Experiment: Our experiments demonstrate SELP\u2019s...", "url": "https://huggingface.co/posts/lin-tan/763019179488759", "date_published": "2025-02-07T17:01:45.531118"}, {"id": "https://huggingface.co/posts/m-ric/410805194640777", "image": "", "title": "Introducing \ud835\uddfc\ud835\uddfd\ud835\uddf2\ud835\uddfb \ud835\uddd7\ud835\uddf2\ud835\uddf2\ud835\uddfd-\ud835\udde5\ud835\uddf2\ud835\ude00\ud835\uddf2\ud835\uddee\ud835\uddff\ud835\uddf0\ud835\uddf5 by Hugging Face! \ud83d\udca5", "content_text": "Introducing \ud835\uddfc\ud835\uddfd\ud835\uddf2\ud835\uddfb \ud835\uddd7\ud835\uddf2\ud835\uddf2\ud835\uddfd-\ud835\udde5\ud835\uddf2\ud835\ude00\ud835\uddf2\ud835\uddee\ud835\uddff\ud835\uddf0\ud835\uddf5 by Hugging Face! \ud83d\udca5 OpenAI's latest agentic app Deep Research seems really good... But it's closed, as usual. \u23f1\ufe0f So with a team of cracked colleagues, we set ourselves a 24hours deadline to replicate and open-source Deep Research! \u23f1\ufe0f \u27a1\ufe0f We built open-Deep-Research, an entirely open agent that can: navigate the web autonomously, scroll and search through pages, download and manipulate files, run calculation on data... We aimed for the best performance: are the agent's answers really rigorous? On GAIA benchmark, Deep Research had 67% accuracy on the validation set. \u27a1\ufe0f open Deep Research is at 55% (powered by o1), it is: - the best pass@1 solution submitted - the best open solution \ud83d\udcaa\ud83d\udcaa And it's only getting started ! Please jump in, drop PRs, and let's bring it to the top ! Read the blog post \ud83d\udc49 https://huggingface.co/blog/open-deep-research See translation", "url": "https://huggingface.co/posts/m-ric/410805194640777", "date_published": "2025-02-07T17:01:45.531562"}, {"id": "https://huggingface.co/posts/AdinaY/234944926747608", "image": "", "title": "Xwen \ud83d\udd25 a series of open models based on Qwen2.5 models, developed by a brilliant research team of PhD students from the Chinese community.", "content_text": "Xwen \ud83d\udd25 a series of open models based on Qwen2.5 models, developed by a brilliant research team of PhD students from the Chinese community. shenzhi-wang/xwen-chat-679e30ab1f4b90cfa7dbc49e \u2728 7B/72B \u2728 Apache 2.0 \u2728 Xwen-72B-Chat outperformed DeepSeek V3 on Arena Hard Auto See translation", "url": "https://huggingface.co/posts/AdinaY/234944926747608", "date_published": "2025-02-07T17:01:45.531861"}, {"id": "https://huggingface.co/posts/nyuuzyou/794560065961999", "image": "", "title": "\ud83d\udcf1 UI Navigation Corpus -", "content_text": "\ud83d\udcf1 UI Navigation Corpus - teleren/ui-navigation-corpus A comprehensive collection of mobile and web UI elements created by a new member of the Hugging Face community @ teleren . I'm glad that I was able to provide a little help together with @ its5Q to get this dataset published. This dataset contains: - Screenshots and recordings of mobile (iOS/Android) and web interfaces - UI navigation annotations and metadata - Screen categorization tags and text extractions - Navigation paths and screen relationships - Version control for UI imagery Perfect for training UI navigation agents and understanding interface patterns. The dataset provides detailed annotations linking screens, sections, and navigation flows together. See translation", "url": "https://huggingface.co/posts/nyuuzyou/794560065961999", "date_published": "2025-02-07T17:01:45.532259"}, {"id": "https://huggingface.co/posts/MonsterMMORPG/594321967336207", "image": "", "title": "Amazing Gradio Batch Processing APP For Newest SOTA Background Remover Open Source Model BiRefNet HR (High Resolution) Published For Windows, RunPod, Massed Compute, and Kaggle", "content_text": "Amazing Gradio Batch Processing APP For Newest SOTA Background Remover Open Source Model BiRefNet HR (High Resolution) Published For Windows, RunPod, Massed Compute, and Kaggle Installers and APP : https://www.patreon.com/posts/121679760 BiRefNet : Bilateral Reference for High-Resolution Dichotomous Image Segmentation BiRefNet recently got some amazing updates and now it has high resolution model (2048x2048) and other speed and VRAM optimizations We have upgraded our existing Gradio APP, added new model and new features Official repo is here : https://github.com/ZhengPeng7/BiRefNet We have published 1-Click installers for Windows, RunPod, Massed Compute and a free Kaggle Account notebook Works great even on free Kaggle account Check out the below attached images to learn more See translation", "url": "https://huggingface.co/posts/MonsterMMORPG/594321967336207", "date_published": "2025-02-07T17:01:45.532605"}, {"id": "https://huggingface.co/posts/IliaLarchenko/621814832633058", "image": "", "title": "I am presenting Decoder-Only Transformer (DOT) Policy a simple Behavioral Control policy that outperforms SOTA models on two simple benchmark tasks:", "content_text": "I am presenting Decoder-Only Transformer (DOT) Policy a simple Behavioral Control policy that outperforms SOTA models on two simple benchmark tasks: \u2705 PushT (pushing an object to a goal) \u2013 84% success on keypoints, 74% on images (previous best: 75% / 69%) \u2705 ALOHA Insert (precise bimanual insertion) \u2013 30% success (previous best: ~21%) The best part? DOT is much smaller (sometimes 100 times less parameters) than previous SOTA models, trains faster, and avoids complexity: \ud83d\udeab No generative models (Diffusion, VAE, GANs) \ud83d\udeab No discretization/tokenization of actions \ud83d\udeab No reinforcement learning or multi-stage training \u2705 Just learns from human demos, plain and simple This is still early \u2014 more complex real-life tasks need testing, and no guarantees it will actually work well there, but I think it's interesting to share. Sometimes, simpler approaches can be just as effective (or even better) than complex ones. \ud83d\udd17 Open-source code and detailed description:...", "url": "https://huggingface.co/posts/IliaLarchenko/621814832633058", "date_published": "2025-02-07T17:01:45.533126"}, {"id": "https://huggingface.co/posts/nicolay-r/887755882993305", "image": "", "title": "\ud83d\udea8 Key takeaway of a quick mastering Sentiment Analysis nowadays. Trough the questionare \ud83d\udcdd of the past RuOpinoinNE-2024 competition we got insights and participants model preference chocies. Our main conclusion:", "content_text": "\ud83d\udea8 Key takeaway of a quick mastering Sentiment Analysis nowadays. Trough the questionare \ud83d\udcdd of the past RuOpinoinNE-2024 competition we got insights and participants model preference chocies. Our main conclusion: \u2728 The submissions of the top performed models exploit Few-shot learning for LLM. Takeaway note comparing with the prior RuSentNE-2023 competition: \ud83e\udde0 Reasoning in steps requires more actions for tweaking. Most recent solutions empowered with Chain-of-Thouhgt are tend to think too much. Earlier we might see improvements for the Flan-T5 (2.8B) in fine-tuned mode but not among the zero-shot approaches. nicolay-r/flan-t5-tsa-thor-xl Related materials: https://github.com/dialogue-evaluation/RuOpinionNE-2024 RuSentNE-2023: Evaluating Entity-Oriented Sentiment Analysis on Russian News Texts (2305.17679) Large Language Models in Targeted Sentiment Analysis (2404.12342) See translation", "url": "https://huggingface.co/posts/nicolay-r/887755882993305", "date_published": "2025-02-07T17:01:45.533551"}, {"id": "https://huggingface.co/posts/victor/435864388294574", "image": "", "title": "Hey everyone, we've given", "content_text": "Hey everyone, we've given https://hf.co/spaces page a fresh update! Smart Search: Now just type what you want to do\u2014like \"make a viral meme\" or \"generate music\"\u2014and our search gets it. New Categories: Check out the cool new filter bar with icons to help you pick a category fast. Redesigned Space Cards: Reworked a bit to really show off the app descriptions, so you know what each Space does at a glance. Random Prompt: Need ideas? Hit the dice button for a burst of inspiration. We\u2019d love to hear what you think\u2014drop us some feedback plz! See translation", "url": "https://huggingface.co/posts/victor/435864388294574", "date_published": "2025-02-07T17:01:45.533914"}]}